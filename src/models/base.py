"""
Base model sƒ±nƒ±fƒ± - T√ºm ML modellerinin parent class'ƒ±.

Bu mod√ºl, projede kullanƒ±lacak t√ºm model'larƒ±n (CatBoost, LightGBM, XGBoost, vb.)
inherit edeceƒüi base class'ƒ± i√ßerir.

Features:
- Abstract methods (build_model)
- Fit, predict, predict_proba
- Model save/load
- Feature importance
- Training history tracking
- Validation support
- Robust prediction handling (string labels ‚Üí integer conversion)

Author: sulegogh
Date: 2025-11-11
Version: 3.0 (Fixed string label prediction issue)
"""

import time
from abc import ABC, abstractmethod
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import joblib
import numpy as np
import pandas as pd
from loguru import logger

from src.core import RANDOM_STATE, TARGET_COLUMN


class BaseModel(ABC):
    """
    Base model sƒ±nƒ±fƒ± (Abstract Base Class).

    T√ºm machine learning model'larƒ± bu class'tan inherit eder.

    Attributes:
        model_name (str): Model ismi (√∂rn: 'CatBoost', 'LightGBM')
        model (Any): Sklearn/XGBoost/LightGBM/CatBoost model objesi
        params (dict): Model hyperparametreleri
        is_trained (bool): Model train edildi mi?
        feature_names (List[str]): Feature isimleri
        training_history (dict): Training metrikleri (loss, accuracy, vb.)
        training_time (float): Training s√ºresi (saniye)
        created_at (str): Model olu≈üturulma zamanƒ±

    Example:
        >>> from src.models import CatBoostModel
        >>> model = CatBoostModel(iterations=500, learning_rate=0.05)
        >>> model.fit(X_train, y_train, X_val, y_val)
        >>> predictions = model.predict(X_test)
    """

    def __init__(self, model_name: str, **params):
        """
        BaseModel ba≈ülat.

        Args:
            model_name: Model ismi (√∂rn: 'CatBoost', 'LightGBM')
            **params: Model hyperparametreleri
        """
        self.model_name = model_name
        self.model: Any | None = None
        self.params = params
        self.is_trained = False
        self.feature_names: list[str] | None = None
        self.training_history: dict[str, Any] = {}
        self.training_time: float | None = None
        self.created_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        logger.info(f"‚ú® {model_name} model olu≈üturuldu")
        logger.debug(f"   Parametreler: {params}")

    @abstractmethod
    def build_model(self) -> Any:
        """
        Model'i olu≈ütur.

        Bu method her child class i√ßin override edilmeli!

        Returns:
            Any: Model objesi (CatBoostClassifier, LGBMClassifier, vb.)

        Raises:
            NotImplementedError: Bu method override edilmemi≈üse
        """
        raise NotImplementedError(f"{self.model_name}.build_model() must be implemented!")

    def fit(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series | np.ndarray,
        X_val: pd.DataFrame | None = None,
        y_val: pd.Series | np.ndarray | None = None,
        **fit_params,
    ) -> "BaseModel":
        """
        Model'i train et.

        Args:
            X_train: Train features (n_samples, n_features)
            y_train: Train target (n_samples,)
            X_val: Validation features (optional)
            y_val: Validation target (optional)
            **fit_params: Ek fit parametreleri (√∂rn: sample_weight, eval_set)

        Returns:
            BaseModel: self (chaining i√ßin)

        Raises:
            ValueError: X_train veya y_train None ise

        Example:
            >>> model.fit(X_train, y_train, X_val, y_val)

        Notes:
            - Child class fit() metodunda eval_set'i fit_params'a ekleyebilir
            - Bu method duplicate eval_set'i √∂nler
        """
        # Input validation
        if X_train is None or y_train is None:
            raise ValueError("X_train ve y_train None olamaz!")

        if len(X_train) != len(y_train):
            raise ValueError(f"X_train ({len(X_train)}) ve y_train ({len(y_train)}) " f"boyutlarƒ± e≈üit deƒüil!")

        logger.info("=" * 60)
        logger.info(f"üöÄ {self.model_name} TRAINING BA≈ûLIYOR")
        logger.info("=" * 60)
        logger.info(f"üìä Train: {len(X_train):,} samples, {len(X_train.columns)} features")

        if X_val is not None and y_val is not None:
            logger.info(f"üìä Val:   {len(X_val):,} samples")
        else:
            logger.warning("‚ö†Ô∏è  Validation set yok! Early stopping kullanƒ±lamaz.")

        # Feature names'i sakla
        self.feature_names = X_train.columns.tolist()

        # Model yoksa olu≈ütur
        if self.model is None:
            self.model = self.build_model()

        # Training ba≈ülangƒ±√ß zamanƒ±
        start_time = time.time()

        # Train et
        try:
            # Child class fit_params'a eval_set eklemi≈ü olabilir (CatBoost gibi)
            # Eƒüer yoksa ve validation set varsa, ekle
            if "eval_set" not in fit_params and X_val is not None and y_val is not None:
                fit_params["eval_set"] = [(X_val, y_val)]
                logger.debug("   eval_set fit_params'a eklendi")

            # Train et (t√ºm parametreler fit_params'da)
            self.model.fit(X_train, y_train, **fit_params)

            # Training s√ºresi
            self.training_time = time.time() - start_time

            self.is_trained = True

            logger.info("=" * 60)
            logger.info(f"‚úÖ {self.model_name} TRAINING TAMAMLANDI")
            logger.info(f"‚è±Ô∏è  S√ºre: {self.training_time:.2f} saniye")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"‚ùå Training hatasƒ±: {e}")
            import traceback

            logger.error(traceback.format_exc())
            raise

        return self

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        Tahmin yap (class labels - INTEGER).

        CatBoost bazen STRING labels d√∂nd√ºr√ºr. Bu method her durumda
        INTEGER class labels (0, 1, 2, ...) d√∂nd√ºr√ºr.

        Strategy:
        1. predict_proba() kullan (her zaman numeric)
        2. argmax ile class labels'a √ßevir
        3. Integer type ensure et

        Args:
            X: Features DataFrame (n_samples, n_features)

        Returns:
            np.ndarray: Predicted class labels (n_samples,) - 1D integer array
                       Values: [0, 1, 2, ...]

        Raises:
            ValueError: Model train edilmemi≈üse

        Example:
            >>> predictions = model.predict(X_test)
            >>> # predictions.shape = (1435,)  # 1D array
            >>> # predictions = [0, 2, 1, 0, ...]  # Integer class labels
            >>> # predictions.dtype = int64
        """
        if not self.is_trained:
            raise ValueError(f"‚ùå {self.model_name} hen√ºz train edilmedi! √ñnce fit() √ßaƒüƒ±rƒ±n.")

        if self.feature_names and len(X.columns) != len(self.feature_names):
            logger.warning(
                f"‚ö†Ô∏è  Feature sayƒ±sƒ± uyu≈ümuyor! " f"Beklenen: {len(self.feature_names)}, Gelen: {len(X.columns)}"
            )

        logger.debug(f"üéØ Tahmin yapƒ±lƒ±yor: {len(X)} sample")

        # STRATEGY: Use predict_proba() + argmax
        # Bu y√∂ntem her zaman integer d√∂nd√ºr√ºr (string labels problemi yok)
        try:
            # Get probabilities (always numeric)
            probabilities = self.model.predict_proba(X)

            # Convert to class labels using argmax
            predictions = np.argmax(probabilities, axis=1)

            logger.debug(f"   ‚úÖ Method: predict_proba() + argmax " f"(avoids string label issues)")
            logger.debug(f"   üìä Probabilities shape: {probabilities.shape}")
            logger.debug(f"   üìä Predictions shape: {predictions.shape}")

        except Exception as e:
            # Fallback: Try direct predict() with conversion
            logger.warning(f"   ‚ö†Ô∏è  predict_proba() failed: {e}. " "Falling back to predict() with conversion.")

            predictions = self.model.predict(X)

            # Convert to numpy if needed
            if not isinstance(predictions, np.ndarray):
                predictions = np.array(predictions)

            # Handle different shapes
            if predictions.ndim == 2:
                if predictions.shape[1] == 1:
                    # (n, 1) ‚Üí (n,)
                    predictions = predictions.flatten()
                else:
                    # (n, k) ‚Üí (n,) via argmax
                    predictions = np.argmax(predictions, axis=1)

            # Convert string labels to integers if needed
            if predictions.dtype == "object" or predictions.dtype.kind == "U":
                logger.debug("   ‚ÑπÔ∏è  String labels detected, converting to integers")

                # Define label mapping
                unique_labels = np.unique(predictions)
                label_mapping = {}

                # Try common string patterns
                if "CANDIDATE" in unique_labels:
                    label_mapping = {"CANDIDATE": 0, "CONFIRMED": 1, "FALSE POSITIVE": 2}
                else:
                    # Generic mapping (alphabetical order)
                    for idx, label in enumerate(sorted(unique_labels)):
                        label_mapping[label] = idx

                # Apply mapping
                predictions = np.array([label_mapping.get(label, -1) for label in predictions])

                logger.debug(f"   ‚ÑπÔ∏è  Label mapping: {label_mapping}")

        # Ensure integer type
        predictions = predictions.astype(int)

        # Validate output
        unique_preds = np.unique(predictions)
        logger.debug(
            f"   ‚úÖ Final predictions: shape={predictions.shape}, "
            f"dtype={predictions.dtype}, unique={unique_preds.tolist()}"
        )

        # Sanity check
        if len(unique_preds) < 2:
            logger.warning(
                f"‚ö†Ô∏è  Only {len(unique_preds)} unique class(es) in predictions! " "Model may be biased or data issue."
            )

        return predictions

    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """
        Tahmin yap (class probabilities).

        Args:
            X: Features DataFrame (n_samples, n_features)

        Returns:
            np.ndarray: Predicted probabilities (n_samples, n_classes)

        Raises:
            ValueError: Model train edilmemi≈üse

        Example:
            >>> probabilities = model.predict_proba(X_test)
            >>> # probabilities.shape = (1435, 3)  # 2D array
            >>> # probabilities[:, 0]  # CANDIDATE probabilities
            >>> # probabilities[:, 1]  # CONFIRMED probabilities
            >>> # probabilities[:, 2]  # FALSE POSITIVE probabilities
        """
        if not self.is_trained:
            raise ValueError(f"‚ùå {self.model_name} hen√ºz train edilmedi! √ñnce fit() √ßaƒüƒ±rƒ±n.")

        logger.debug(f"üéØ Probability tahminleri yapƒ±lƒ±yor: {len(X)} sample")

        probabilities = self.model.predict_proba(X)

        logger.debug(f"   üìä Probabilities shape: {probabilities.shape if hasattr(probabilities, 'shape') else 'N/A'}")

        return probabilities

    def get_feature_importance(self, importance_type: str = "gain") -> pd.DataFrame:
        """
        Feature importance al.

        Args:
            importance_type: 'gain', 'split', 'weight' (model'e g√∂re deƒüi≈üir)

        Returns:
            pd.DataFrame: feature, importance columns ile DataFrame

        Raises:
            ValueError: Model train edilmemi≈üse veya importance desteklenmiyorsa

        Example:
            >>> importance_df = model.get_feature_importance()
            >>> print(importance_df.head(10))
        """
        if not self.is_trained:
            raise ValueError(f"‚ùå {self.model_name} hen√ºz train edilmedi!")

        if not hasattr(self.model, "feature_importances_"):
            logger.warning(f"‚ö†Ô∏è  {self.model_name} feature importance desteklemiyor")
            return pd.DataFrame()

        importance_df = (
            pd.DataFrame({"feature": self.feature_names, "importance": self.model.feature_importances_})
            .sort_values("importance", ascending=False)
            .reset_index(drop=True)
        )

        return importance_df

    def save(self, filepath: str | Path, compress: bool = True) -> None:
        """
        Model'i kaydet (pickle format).

        Note:
            Bu method child class'larda override edilebilir.
            √ñrneƒüin CatBoostModel kendi save() metodunu kullanƒ±r.

        Args:
            filepath: Model dosya yolu (.pkl veya .joblib)
            compress: Sƒ±kƒ±≈ütƒ±rma kullan (daha k√º√ß√ºk dosya)

        Raises:
            ValueError: Model train edilmemi≈üse

        Example:
            >>> model.save("models/catboost_20251111.pkl")
        """
        if not self.is_trained:
            raise ValueError(f"‚ùå {self.model_name} hen√ºz train edilmedi!")

        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)

        # Model data
        model_data = {
            "model": self.model,
            "model_name": self.model_name,
            "params": self.params,
            "feature_names": self.feature_names,
            "training_history": self.training_history,
            "training_time": self.training_time,
            "created_at": self.created_at,
            "is_trained": self.is_trained,
        }

        # Kaydet
        compression = 3 if compress else 0
        joblib.dump(model_data, filepath, compress=compression)

        file_size = filepath.stat().st_size / (1024 * 1024)  # MB
        logger.info(f"üíæ Model kaydedildi: {filepath} ({file_size:.2f} MB)")

    @staticmethod
    def load(filepath: str | Path) -> "BaseModel":
        """
        Model'i y√ºkle (pickle format).

        Note:
            Bu method child class'larda override edilmeli.
            CatBoostModel kendi load() metodunu kullanƒ±r.

        Args:
            filepath: Model dosya yolu (.pkl veya .joblib)

        Returns:
            BaseModel: Loaded model instance

        Raises:
            FileNotFoundError: Model dosyasƒ± bulunamazsa

        Example:
            >>> model = BaseModel.load("models/catboost_20251111.pkl")
        """
        filepath = Path(filepath)

        if not filepath.exists():
            raise FileNotFoundError(f"‚ùå Model dosyasƒ± bulunamadƒ±: {filepath}")

        # Y√ºkle
        model_data = joblib.load(filepath)

        # Create new instance (type based on model_name)
        # This is a fallback - child classes should override this method
        from src.models.catboost_model import CatBoostModel

        model_name = model_data.get("model_name", "Unknown")

        if model_name == "CatBoost":
            instance = CatBoostModel()
        else:
            # Generic loading (not recommended, child class should override)
            logger.warning(f"‚ö†Ô∏è  Generic loading for {model_name}. " "Child class should override load() method.")
            instance = object.__new__(BaseModel)
            instance.__init__(model_name=model_name)

        # Restore attributes
        instance.model = model_data["model"]
        instance.model_name = model_data["model_name"]
        instance.params = model_data["params"]
        instance.feature_names = model_data["feature_names"]
        instance.training_history = model_data.get("training_history", {})
        instance.training_time = model_data.get("training_time")
        instance.created_at = model_data.get("created_at", "Unknown")
        instance.is_trained = model_data.get("is_trained", True)

        file_size = filepath.stat().st_size / (1024 * 1024)  # MB
        logger.info(f"üìÇ Model y√ºklendi: {filepath} ({file_size:.2f} MB)")
        logger.info(f"   Created: {instance.created_at}")
        if instance.training_time:
            logger.info(f"   Training time: {instance.training_time:.2f}s")

        return instance

    def get_params(self) -> dict[str, Any]:
        """
        Model parametrelerini al.

        Returns:
            dict: Model parametreleri
        """
        return self.params.copy()

    def set_params(self, **params) -> None:
        """
        Model parametrelerini g√ºncelle.

        Args:
            **params: Yeni parametreler
        """
        self.params.update(params)
        logger.info(f"üîß Parametreler g√ºncellendi: {params}")

    def __repr__(self) -> str:
        """String representation."""
        status = "‚úÖ Trained" if self.is_trained else "‚è≥ Not Trained"
        return f"{self.model_name}({status})"

    def __str__(self) -> str:
        """User-friendly string representation."""
        lines = [
            "=" * 50,
            f"{self.model_name} Model",
            "=" * 50,
            f"Status:        {self.__repr__()}",
            f"Created:       {self.created_at}",
            f"Features:      {len(self.feature_names) if self.feature_names else 'N/A'}",
            f"Training Time: {self.training_time:.2f}s" if self.training_time else "Training Time: N/A",
            "=" * 50,
        ]
        return "\n".join(lines)
