#!/usr/bin/env python3
"""
NASA Kepler KOI verisini indir.

Bu script, NASA Exoplanet Archive API'den Kepler Objects of Interest (KOI)
tablosunu indirir ve yerel 'data/raw/' dizinine kaydeder.

KullanÄ±m:
    python scripts/download_nasa_data.py
    
    # Veya Makefile ile:
    make download-data

Ortam DeÄŸiÅŸkenleri:
    NASA_API_KEY: NASA API anahtarÄ± (.env dosyasÄ±ndan okunur)
"""

import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional

# Proje kÃ¶k dizinini Python path'e ekle
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Standart kÃ¼tÃ¼phaneler
import requests
import pandas as pd
from dotenv import load_dotenv
from tqdm import tqdm

# Proje modÃ¼lleri
from src.core import (
    DATA_RAW,
    NASA_API_BASE_URL,
    NASA_TABLE_NAME,
    NASA_OUTPUT_FORMAT,
    TARGET_COLUMN,
    DataDownloadError,
    DataValidationError,
)


# ============================================
# KONFÄ°GÃœRASYON
# ============================================

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# NASA API ayarlarÄ±
NASA_API_KEY = os.getenv("NASA_API_KEY", "DEMO_KEY")
OUTPUT_FILE = DATA_RAW / "kepler_koi.csv"
TIMEOUT_SECONDS = 300  # 5 dakika


# ============================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================

def print_header():
    """Script baÅŸlÄ±ÄŸÄ±nÄ± yazdÄ±r."""
    print("=" * 70)
    print("ğŸª NASA KEPLER KOI VERÄ° Ä°NDÄ°RME")
    print("=" * 70)
    print(f"ğŸ“… Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”‘ API Key: {NASA_API_KEY[:8]}..." if len(NASA_API_KEY) > 8 else "DEMO_KEY")
    print(f"ğŸ“‚ Hedef: {OUTPUT_FILE}")
    print("=" * 70)
    print()


def check_prerequisites():
    """Ã–n gereksinimleri kontrol et."""
    print("ğŸ” Ã–n kontroller yapÄ±lÄ±yor...")
    
    # Data dizini var mÄ±?
    if not DATA_RAW.exists():
        print(f"  âš ï¸  {DATA_RAW} dizini bulunamadÄ±, oluÅŸturuluyor...")
        DATA_RAW.mkdir(parents=True, exist_ok=True)
        print(f"  âœ“ Dizin oluÅŸturuldu: {DATA_RAW}")
    else:
        print(f"  âœ“ Data dizini mevcut: {DATA_RAW}")
    
    # Eski dosya var mÄ±?
    if OUTPUT_FILE.exists():
        file_size = OUTPUT_FILE.stat().st_size / (1024 * 1024)  # MB
        file_mtime = datetime.fromtimestamp(OUTPUT_FILE.stat().st_mtime)
        print(f"  âš ï¸  Mevcut dosya bulundu:")
        print(f"     Boyut: {file_size:.2f} MB")
        print(f"     Tarih: {file_mtime.strftime('%Y-%m-%d %H:%M:%S')}")
        
        response = input("  â“ Ãœzerine yazmak istiyor musunuz? [y/N]: ")
        if response.lower() != 'y':
            print("  â„¹ï¸  Ä°ndirme iptal edildi.")
            sys.exit(0)
        print("  âœ“ Eski dosya silinecek")
    
    # API anahtarÄ± kontrolÃ¼
    if NASA_API_KEY == "DEMO_KEY":
        print("  âš ï¸  DEMO_KEY kullanÄ±lÄ±yor (gÃ¼nde 30 request limiti)")
        print("     GerÃ§ek API key iÃ§in: https://api.nasa.gov/")
    else:
        print(f"  âœ“ API Key yapÄ±landÄ±rÄ±lmÄ±ÅŸ")
    
    print()


def build_api_url() -> str:
    """
    NASA Exoplanet Archive API URL'ini oluÅŸtur.
    
    Returns:
        str: Tam API URL
    """
    params = {
        "table": NASA_TABLE_NAME,
        "format": NASA_OUTPUT_FORMAT,
        "select": "*",  # TÃ¼m sÃ¼tunlarÄ± al
    }
    
    # URL parametrelerini oluÅŸtur
    param_str = "&".join([f"{k}={v}" for k, v in params.items()])
    url = f"{NASA_API_BASE_URL}?{param_str}"
    
    return url


def download_data(url: str) -> Optional[str]:
    """
    NASA API'den veri indir.
    
    Args:
        url: Ä°ndirme URL'i
        
    Returns:
        str: Ä°ndirilen CSV verisi (string)
        
    Raises:
        DataDownloadError: Ä°ndirme baÅŸarÄ±sÄ±z olursa
    """
    print("ğŸ“¥ Veri indiriliyor...")
    print(f"   URL: {url}")
    print()
    
    try:
        # Request gÃ¶nder (stream=True ile progress bar iÃ§in)
        response = requests.get(url, timeout=TIMEOUT_SECONDS, stream=True)
        response.raise_for_status()
        
        # Total boyutu al (varsa)
        total_size = int(response.headers.get('content-length', 0))
        
        # Progress bar ile indir
        chunk_size = 8192  # 8KB chunks
        chunks = []
        
        with tqdm(
            total=total_size,
            unit='B',
            unit_scale=True,
            desc='  Ä°ndiriliyor',
            ncols=80
        ) as pbar:
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    chunks.append(chunk)
                    pbar.update(len(chunk))
        
        # TÃ¼m chunk'larÄ± birleÅŸtir
        data = b''.join(chunks).decode('utf-8')
        
        print(f"  âœ“ Ä°ndirme tamamlandÄ±: {len(data) / (1024*1024):.2f} MB")
        print()
        
        return data
        
    except requests.exceptions.Timeout:
        raise DataDownloadError(
            f"Ä°ndirme zaman aÅŸÄ±mÄ±na uÄŸradÄ± ({TIMEOUT_SECONDS}s)"
        )
    except requests.exceptions.RequestException as e:
        raise DataDownloadError(f"Ä°ndirme hatasÄ±: {str(e)}")
    except Exception as e:
        raise DataDownloadError(f"Beklenmeyen hata: {str(e)}")


def validate_data(df: pd.DataFrame):
    """
    Ä°ndirilen veriyi doÄŸrula.
    
    Args:
        df: Pandas DataFrame
        
    Raises:
        DataValidationError: DoÄŸrulama baÅŸarÄ±sÄ±z olursa
    """
    print("ğŸ” Veri doÄŸrulamasÄ± yapÄ±lÄ±yor...")
    
    # BoÅŸ mu?
    if df.empty:
        raise DataValidationError("DataFrame boÅŸ!")
    
    print(f"  âœ“ SatÄ±r sayÄ±sÄ±: {len(df):,}")
    print(f"  âœ“ SÃ¼tun sayÄ±sÄ±: {len(df.columns)}")
    
    # Target sÃ¼tunu var mÄ±?
    if TARGET_COLUMN not in df.columns:
        raise DataValidationError(
            f"Target sÃ¼tunu '{TARGET_COLUMN}' bulunamadÄ±!"
        )
    print(f"  âœ“ Target sÃ¼tunu mevcut: {TARGET_COLUMN}")
    
    # Target daÄŸÄ±lÄ±mÄ±
    target_dist = df[TARGET_COLUMN].value_counts()
    print(f"  âœ“ Target daÄŸÄ±lÄ±mÄ±:")
    for value, count in target_dist.items():
        pct = (count / len(df)) * 100
        print(f"     {value}: {count:,} (%{pct:.1f})")
    
    # Missing values
    total_missing = df.isnull().sum().sum()
    missing_pct = (total_missing / (len(df) * len(df.columns))) * 100
    print(f"  âœ“ Toplam eksik deÄŸer: {total_missing:,} (%{missing_pct:.1f})")
    
    # Memory kullanÄ±mÄ±
    memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)
    print(f"  âœ“ Memory kullanÄ±mÄ±: {memory_mb:.2f} MB")
    
    print()


def save_data(data: str, output_path: Path):
    """
    Veriyi dosyaya kaydet.
    
    Args:
        data: CSV verisi (string)
        output_path: KayÄ±t yolu
    """
    print(f"ğŸ’¾ Veri kaydediliyor: {output_path}")
    
    # Dizin yoksa oluÅŸtur
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Dosyaya yaz
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(data)
    
    # Dosya boyutunu gÃ¶ster
    file_size = output_path.stat().st_size / (1024 * 1024)
    print(f"  âœ“ Kaydedildi: {file_size:.2f} MB")
    print()


def print_summary(df: pd.DataFrame, elapsed_time: float):
    """
    Ã–zet bilgileri yazdÄ±r.
    
    Args:
        df: Pandas DataFrame
        elapsed_time: GeÃ§en sÃ¼re (saniye)
    """
    print("=" * 70)
    print("ğŸ“Š Ã–ZET")
    print("=" * 70)
    print(f"âœ… Ä°ndirme baÅŸarÄ±lÄ±!")
    print(f"ğŸ“‚ Dosya: {OUTPUT_FILE}")
    print(f"ğŸ“ Boyut: {OUTPUT_FILE.stat().st_size / (1024*1024):.2f} MB")
    print(f"ğŸ“Š SatÄ±r: {len(df):,}")
    print(f"ğŸ“Š SÃ¼tun: {len(df.columns)}")
    print(f"â±ï¸  SÃ¼re: {elapsed_time:.1f} saniye")
    print("=" * 70)
    print()
    print("ğŸ‰ Sonraki adÄ±m: Exploratory Data Analysis (EDA)")
    print("   make run-jupyter")
    print("   notebooks/01_exploratory_data_analysis.ipynb")
    print()


# ============================================
# ANA FONKSÄ°YON
# ============================================

def main():
    """Ana indirme fonksiyonu."""
    from time import time
    
    start_time = time()
    
    try:
        # BaÅŸlÄ±k
        print_header()
        
        # Ã–n kontroller
        check_prerequisites()
        
        # API URL'i oluÅŸtur
        url = build_api_url()
        
        # Veriyi indir
        data = download_data(url)
        
        # CSV'yi pandas'a yÃ¼kle
        print("ğŸ“Š Veri parse ediliyor...")
        df = pd.read_csv(
            pd.io.common.StringIO(data),
            comment='#',  # Yorum satÄ±rlarÄ±nÄ± atla
            low_memory=False
        )
        print(f"  âœ“ Parse tamamlandÄ±")
        print()
        
        # DoÄŸrulama
        validate_data(df)
        
        # Kaydet
        save_data(data, OUTPUT_FILE)
        
        # Ã–zet
        elapsed_time = time() - start_time
        print_summary(df, elapsed_time)
        
        return 0
        
    except DataDownloadError as e:
        print(f"\nâŒ Ä°ndirme hatasÄ±: {e}")
        return 1
        
    except DataValidationError as e:
        print(f"\nâŒ DoÄŸrulama hatasÄ±: {e}")
        return 1
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Ä°ndirme kullanÄ±cÄ± tarafÄ±ndan iptal edildi.")
        return 130
        
    except Exception as e:
        print(f"\nâŒ Beklenmeyen hata: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())